# IconsAI - Ecossistema de Sistemas Inteligentes

## ğŸš¨ REGRAS CRÃTICAS (SEMPRE SEGUIR)

### 1. QUESTIONAR ANTES DE AGIR
- **NUNCA** assuma compreensÃ£o completa
- **SEMPRE** criar questionÃ¡rio de validaÃ§Ã£o antes de implementar
- **SEMPRE** perguntar quando houver dÃºvidas, mesmo com bypass ativado
- **SEMPRE** explicar o que foi compreendido antes de comeÃ§ar

### 2. CÃLCULOS E PROCESSAMENTO
- âŒ **NEVER**: CÃ¡lculos matemÃ¡ticos no frontend/JavaScript
- âœ… **ALWAYS**: Todos os cÃ¡lculos em Python no backend
- âŒ **NEVER**: Dados hardcoded em cÃ³digo
- âœ… **ALWAYS**: Dados vindos de APIs/banco de dados

### 3. GESTÃƒO DE VOZ (TTS)
- âŒ **NEVER**: Usar voz do browser (window.speechSynthesis)
- âœ… **ALWAYS**: Usar OpenAI TTS (gpt-4o-mini-tts) ou ElevenLabs
- âœ… **ALWAYS**: Aplicar humanizaÃ§Ã£o conforme mÃ³dulo (ver seÃ§Ã£o Voice)
- âœ… **ALWAYS**: Incluir instruÃ§Ãµes de voz personalizadas

### 4. RASTREABILIDADE DE DADOS
- âœ… **ALWAYS**: Toda informaÃ§Ã£o precisa ter fonte registrada
- âœ… **ALWAYS**: Criar/atualizar tabela `fontes_dados` em TODOS os projetos
- âœ… **ALWAYS**: Incluir: fonte, URL, data coleta, periodicidade

### 5. MUDANÃ‡AS NÃƒO SOLICITADAS
- âŒ **NEVER**: Alterar cÃ³digo que nÃ£o foi pedido
- âŒ **NEVER**: "Melhorar" cÃ³digo sem autorizaÃ§Ã£o explÃ­cita
- âœ… **ONLY**: Fazer exatamente o que foi solicitado
- âœ… **IF**: SugestÃµes â†’ perguntar antes de implementar

### 6. ENGENHARIA DE SOFTWARE
- âœ… **ALWAYS**: Seguir SOLID principles
- âœ… **ALWAYS**: CÃ³digo testÃ¡vel e modular
- âœ… **ALWAYS**: TypeScript strict mode (frontend)
- âœ… **ALWAYS**: Type hints obrigatÃ³rios (Python)
- âœ… **ALWAYS**: ValidaÃ§Ã£o com Zod (TS) ou Pydantic (Python)

### 7. SEPARAÃ‡ÃƒO FRONTEND/BACKEND (CRÃTICO)
- âŒ **NEVER**: Processar dados no frontend
- âŒ **NEVER**: CÃ¡lculos, embeddings, IA, ETL no React
- âŒ **NEVER**: LÃ³gica de negÃ³cio no cliente
- âœ… **ALWAYS**: Frontend = UI + chamadas HTTP APENAS
- âœ… **ALWAYS**: Backend = Processamento, LÃ³gica, Dados, IA
- âœ… **ALWAYS**: Separar estrutura de cÃ³digo backend/frontend

### 8. SEGURANÃ‡A
- âŒ **NEVER**: Expor secrets em cÃ³digo
- âŒ **NEVER**: SQL direto sem prepared statements
- âœ… **ALWAYS**: Validar input do usuÃ¡rio
- âœ… **ALWAYS**: Sanitizar dados antes de armazenar
- âœ… **ALWAYS**: Usar variÃ¡veis de ambiente

---

## ğŸ“ ESTRUTURA DOS PROJETOS

### Projetos Principais

```
iconsai-ecosystem/
â”œâ”€â”€ iconsai-production/     â†’ Sidebar/Admin (Vite + React + TS)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     â†’ UI components (shadcn/ui)
â”‚   â”‚   â”œâ”€â”€ modules/        â†’ Feature modules
â”‚   â”‚   â”‚   â””â”€â”€ pwa-voice/  â†’ Voice system (TTS/STT)
â”‚   â”‚   â”œâ”€â”€ config/         â†’ voice-config.ts (presets)
â”‚   â”‚   â”œâ”€â”€ services/       â†’ API integration
â”‚   â”‚   â””â”€â”€ utils/          â†’ Helpers
â”‚   â””â”€â”€ supabase/           â†’ Edge Functions
â”‚
â”œâ”€â”€ orcamento-fiscal-municipios/ â†’ AnÃ¡lise Fiscal (MAIS BEM ESTRUTURADO)
â”‚   â”œâ”€â”€ backend/            â†’ Python microservices
â”‚   â”œâ”€â”€ src/                â†’ React frontend
â”‚   â”œâ”€â”€ scripts/            â†’ ETL scripts (Python)
â”‚   â”œâ”€â”€ mcp-servers/        â†’ MCP integrations (SICONFI, etc)
â”‚   â”œâ”€â”€ services/           â†’ Microservices (Docker)
â”‚   â”‚   â”œâ”€â”€ tts-service/    â†’ Voice synthesis
â”‚   â”‚   â”œâ”€â”€ auth-service/   â†’ Authentication
â”‚   â”‚   â”œâ”€â”€ api-gateway/    â†’ Gateway
â”‚   â”‚   â””â”€â”€ geo-service/    â†’ Geographic data
â”‚   â””â”€â”€ docs/               â†’ Documentation (FONTES_DADOS.md)
â”‚
â””â”€â”€ scraping-hub/           â†’ Web Scraping (MAIS PROBLEMÃTICO)
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ scrapers/       â†’ Scrapers individuais
    â”‚   â”œâ”€â”€ services/       â†’ Business logic
    â”‚   â””â”€â”€ database/       â†’ DB models
    â”œâ”€â”€ api/                â†’ FastAPI routes
    â””â”€â”€ tests/              â†’ pytest tests
```

### Status dos Projetos

| Projeto | Status | Stack | Principais Desafios |
|---------|--------|-------|---------------------|
| **orcamento-fiscal-municipios** | âœ… Melhor estruturado | React + Python + Supabase | CÃ¡lculos complexos, ETL massivo |
| **iconsai-production** | âš ï¸ Adequado | React + TS + Supabase | GestÃ£o de voz, mÃºltiplos mÃ³dulos |
| **scraping-hub** | âš ï¸ ProblemÃ¡tico | Python + FastAPI | Quebra frequente, manutenÃ§Ã£o alta |

---

## ğŸ¯ STACK TECNOLÃ“GICA

### Frontend (iconsai-production, orcamento-fiscal)
```typescript
// Stack principal
- Vite + React 18
- TypeScript 5+ (strict mode)
- shadcn/ui + Radix UI
- TailwindCSS + Framer Motion
- Zustand (state management)
- React Query (@tanstack/react-query)
- Zod (validation)
```

### Backend (microservices)
```python
# Stack principal
- Python 3.11+
- FastAPI (async/await)
- Pydantic (validation)
- SQLAlchemy (ORM)
- Pytest (testing)
- Docker + Docker Compose
```

### Database & Infrastructure
```
- Supabase (PostgreSQL + Edge Functions)
- n8n (automaÃ§Ã£o)
- DigitalOcean (hospedagem)
```

---

## ğŸ—ï¸ ARQUITETURA BACKEND (CRÃTICO)

### PrincÃ­pio Fundamental
```
SEPARAÃ‡ÃƒO ABSOLUTA:
Backend = Processamento, LÃ³gica, Dados, IA
Frontend = UI, ApresentaÃ§Ã£o, InteraÃ§Ã£o

NUNCA processar/calcular/embeddings/IA no frontend
```

### Arquitetura em 3 Camadas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React/TS)                   â”‚
â”‚              Apenas UI e chamadas HTTP                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/REST
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAMADA 1: API Gateway (Node.js)            â”‚
â”‚    â€¢ AutenticaÃ§Ã£o (JWT)                                 â”‚
â”‚    â€¢ Rate limiting                                      â”‚
â”‚    â€¢ ValidaÃ§Ã£o de input                                 â”‚
â”‚    â€¢ Roteamento                                         â”‚
â”‚    â€¢ Logging/Auditoria                                  â”‚
â”‚    â€¢ WebSocket/SSE (realtime)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                          â”‚
             â†“                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAMADA 2: ServiÃ§os     â”‚  â”‚ CAMADA 3: Processamento      â”‚
â”‚ Internos (Node/Python) â”‚  â”‚ Pesado (Python)              â”‚
â”‚                        â”‚  â”‚                              â”‚
â”‚ â€¢ LÃ³gica de negÃ³cio    â”‚  â”‚ â€¢ RAG (ingestÃ£o + retrieval) â”‚
â”‚ â€¢ IntegraÃ§Ãµes APIs     â”‚  â”‚ â€¢ Embeddings/Rerank          â”‚
â”‚ â€¢ Workflows            â”‚  â”‚ â€¢ ETL/CRON                   â”‚
â”‚ â€¢ OrquestraÃ§Ã£o         â”‚  â”‚ â€¢ EstatÃ­stica/Analytics      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ Workers (filas)            â”‚
         â”‚                  â”‚ â€¢ Whisper/TTS                â”‚
         â†“                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Supabase PostgreSQL                         â”‚
â”‚    â€¢ Dados transacionais                                â”‚
â”‚    â€¢ pgvector (RAG)                                     â”‚
â”‚    â€¢ PostGIS (geolocalizaÃ§Ã£o)                           â”‚
â”‚    â€¢ Materialized Views (analytics prÃ©-computadas)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DECISÃ•ES DE BACKEND: Node.js vs Python

### Regras de Bolso (MEMORIZE)

```
ğŸ”¥ GARGALO Ã‰ CONEXÃƒO/ESPERA â†’ Node.js
ğŸ”¥ GARGALO Ã‰ CÃLCULO/MODELO/DADO â†’ Python  
ğŸ”¥ TEM OS DOIS â†’ Node na borda + Python no nÃºcleo
```

### Use Node.js Quando:

âœ… **I/O-bound**: Muitas chamadas a banco, cache, APIs externas  
âœ… **Alta concorrÃªncia**: Muitas requisiÃ§Ãµes simultÃ¢neas (1000+ req/s)  
âœ… **Baixa latÃªncia**: Resposta < 100ms requerida  
âœ… **Realtime**: WebSocket, SSE, notificaÃ§Ãµes push, streaming de eventos  
âœ… **API Gateway**: OrquestraÃ§Ã£o, roteamento, autenticaÃ§Ã£o, rate limiting  
âœ… **Serverless**: Lambda, Edge Functions (cold start ~100ms)  
âœ… **BFF**: Backend-for-Frontend agregando mÃºltiplos serviÃ§os

**PadrÃµes Node.js:**
```typescript
// 1. API Gateway/Orquestrador
app.get('/api/municipios/:id/fiscal', async (req, res) => {
  // Valida, autentica, rate limit
  await validateAuth(req);
  await checkRateLimit(req.user.id);
  
  // Orquestra mÃºltiplos serviÃ§os
  const [dados, indicadores, tendencias] = await Promise.all([
    fetchDadosMunicipio(id),
    pythonService.calcularIndicadores(id),  // â† Chama Python
    supabase.from('tendencias_cache').select()
  ]);
  
  res.json({ dados, indicadores, tendencias });
});

// 2. Realtime (WebSocket)
io.on('connection', (socket) => {
  socket.on('subscribe:municipio', async (codigoIbge) => {
    // Cliente se inscreve para updates
    socket.join(`municipio:${codigoIbge}`);
  });
});

// 3. AutenticaÃ§Ã£o
app.post('/auth/login', async (req, res) => {
  const user = await validateCredentials(req.body);
  const token = jwt.sign({ userId: user.id }, SECRET);
  res.json({ token });
});
```

---

### Use Python Quando:

âœ… **CPU-bound**: CÃ¡lculos matemÃ¡ticos, estatÃ­stica, ML, transformaÃ§Ãµes pesadas  
âœ… **AI/ML/LLM**: RAG (ingestÃ£o + retrieval + rerank), embeddings, classificaÃ§Ã£o  
âœ… **NLP/Audio**: Whisper (STT), anÃ¡lise de sentimento, NER, traduÃ§Ã£o  
âœ… **ETL**: Pipelines de dados, normalizaÃ§Ã£o, deduplicaÃ§Ã£o, transformaÃ§Ã£o massiva  
âœ… **Analytics**: CorrelaÃ§Ãµes, tendÃªncias, sazonalidade, regressÃµes, clustering  
âœ… **Workers**: Processamento assÃ­ncrono em filas (jobs pesados)  
âœ… **Batch Jobs**: CRON contÃ­nuo, processamento noturno, full table scans  
âœ… **Data Science**: NumPy, Pandas, SciPy, statsmodels, scikit-learn

**PadrÃµes Python:**
```python
# 1. ServiÃ§o RAG
@app.post("/rag/ingest")
async def ingest_document(file: UploadFile):
    """Processa documento para RAG (NUNCA no frontend)"""
    
    # 1. Extrai texto
    text = await extract_text(file)
    
    # 2. Chunking
    chunks = chunk_text(text, chunk_size=512, overlap=50)
    
    # 3. Embeddings (OpenAI/local)
    embeddings = await generate_embeddings(chunks)
    
    # 4. Armazena no pgvector
    await db.execute(
        "INSERT INTO embeddings (chunk, embedding, metadata) VALUES ($1, $2, $3)",
        chunks, embeddings, metadata
    )
    
    return {"status": "success", "chunks": len(chunks)}

# 2. Analytics/EstatÃ­stica
@app.get("/analytics/tendencias/{codigo_ibge}")
async def calcular_tendencias(codigo_ibge: str):
    """CÃ¡lculos estatÃ­sticos pesados (NUNCA no frontend)"""
    
    # Busca dados histÃ³ricos
    dados = await fetch_historical_data(codigo_ibge)
    
    # AnÃ¡lise estatÃ­stica
    import numpy as np
    from scipy import stats
    
    # TendÃªncia linear
    x = np.arange(len(dados))
    y = np.array([d.valor for d in dados])
    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
    
    # Sazonalidade
    from statsmodels.tsa.seasonal import seasonal_decompose
    decomposition = seasonal_decompose(y, model='additive', period=12)
    
    # Armazena resultado em cache
    await db.execute(
        "INSERT INTO tendencias_cache (codigo_ibge, slope, r2, data) VALUES ($1, $2, $3, NOW())",
        codigo_ibge, slope, r_value**2
    )
    
    return {
        "tendencia": "crescente" if slope > 0 else "decrescente",
        "r2": r_value**2,
        "sazonalidade": decomposition.seasonal.tolist()
    }

# 3. Worker ETL (Celery/RQ)
@celery.task
def process_siconfi_batch(municipios: list[str]):
    """Worker assÃ­ncrono - processa em background"""
    
    for codigo_ibge in municipios:
        # ETL pesado
        data = fetch_siconfi_api(codigo_ibge)
        normalized = normalize_data(data)
        validate_and_save(normalized)
        
        # Atualiza cache de indicadores
        recalculate_indicators(codigo_ibge)
```

---

### Arquitetura HÃ­brida (RECOMENDADO)

#### Quando Usar HÃ­brido:
- âœ… API pÃºblica grande e concorrente
- âœ… NÃºcleo de IA/processamento pesado
- âœ… CRON contÃ­nuo + ETL + analytics
- âœ… SeparaÃ§Ã£o clara de responsabilidades

#### DivisÃ£o Clara:

**Node.js (Borda/Edge):**
- API externa pÃºblica
- AutenticaÃ§Ã£o (JWT, OAuth)
- Rate limiting por tenant/API key
- Auditoria e logging (request_id, user_id, tenant_id)
- Roteamento e validaÃ§Ã£o de input
- WebSocket/SSE (realtime)
- Chamadas para serviÃ§os internos Python

**Python (NÃºcleo AnalÃ­tico):**
- RAG (ingestÃ£o + retrieval + ranking)
- Embeddings e re-ranking
- TranscriÃ§Ã£o (Whisper), NLP
- Jobs batch/ETL (CRON)
- Workers assÃ­ncronos (filas)
- EstatÃ­stica, ML, Analytics
- Processamento pesado (> 1s)

#### IntegraÃ§Ã£o:

```
OpÃ§Ã£o 1: HTTP/REST (simples)
Node â”€â”€HTTPâ”€â”€> Python FastAPI

OpÃ§Ã£o 2: gRPC (alta performance)
Node â”€â”€gRPCâ”€â”€> Python gRPC Server

OpÃ§Ã£o 3: Fila/Eventos (robusto, RECOMENDADO)
Node â”€â”€publishâ”€â”€> Redis Queue â”€â”€consumeâ”€â”€> Python Workers
```

**Fluxo HÃ­brido TÃ­pico:**

```
Cliente â†’ Node.js Gateway â†’ Python Services â†’ PostgreSQL
                â†“
            Redis Queue
                â†“
          Python Workers
```

**Fluxo TÃ­pico:**
```typescript
// Node.js - API pÃºblica (rÃ¡pida)
app.post('/api/municipios/analisar', async (req, res) => {
  const { codigoIbge, periodo } = req.body;
  
  // 1. Valida
  await validateRequest(req);
  
  // 2. Publica job na fila (nÃ£o espera processar)
  const jobId = await queue.add('analise-fiscal', {
    codigoIbge,
    periodo,
    userId: req.user.id
  });
  
  // 3. Responde imediatamente
  res.json({ 
    jobId, 
    status: 'processing',
    estimatedTime: '30s'
  });
});

// Cliente pode consultar status
app.get('/api/jobs/:id', async (req, res) => {
  const job = await queue.getJob(req.params.id);
  res.json({ 
    status: job.status, 
    progress: job.progress,
    result: job.returnvalue 
  });
});
```

```python
# Python - Worker (processa pesado)
@celery.task(bind=True)
def analise_fiscal_completa(self, codigo_ibge: str, periodo: str):
    """Processa anÃ¡lise fiscal completa"""
    
    # Atualiza progresso
    self.update_state(state='PROGRESS', meta={'progress': 10})
    
    # 1. Coleta dados
    rreo = fetch_rreo(codigo_ibge, periodo)
    rgf = fetch_rgf(codigo_ibge, periodo)
    self.update_state(state='PROGRESS', meta={'progress': 30})
    
    # 2. Calcula indicadores
    indicadores = calcular_indicadores_lrf(rreo, rgf)
    self.update_state(state='PROGRESS', meta={'progress': 60})
    
    # 3. AnÃ¡lise estatÃ­stica
    tendencias = calcular_tendencias_historicas(codigo_ibge)
    correlacoes = calcular_correlacoes(indicadores)
    self.update_state(state='PROGRESS', meta={'progress': 90})
    
    # 4. Armazena resultado
    await save_analysis_result(codigo_ibge, {
        'indicadores': indicadores,
        'tendencias': tendencias,
        'correlacoes': correlacoes,
        'timestamp': datetime.utcnow()
    })
    
    return {'status': 'completed', 'codigo_ibge': codigo_ibge}
```

---

## ğŸ¯ BLUEPRINT COMPLETO - MICROSERVICES

### ServiÃ§o 1: API Gateway (Node.js)

**Responsabilidades:**
- AutenticaÃ§Ã£o (JWT)
- Rate limiting por tenant/API key
- ValidaÃ§Ã£o de input (Zod)
- Logging estruturado (request_id, user_id, tenant_id)
- Versionamento (/v1, /v2)
- Circuit breaker para serviÃ§os internos
- CORS, HTTPS, security headers

**Stack:**
- NestJS ou Fastify
- Redis (rate limit + session)
- Zod (validation)
- Winston (logging)

**Endpoints Externos:**
```typescript
GET    /v1/municipios/:codigo_ibge
GET    /v1/municipios/:codigo_ibge/fiscal
POST   /v1/municipios/:codigo_ibge/analisar
GET    /v1/tendencias/:codigo_ibge
GET    /v1/comparar?codigos=1234567,7654321
POST   /v1/rag/query
GET    /v1/jobs/:job_id
```

**NÃƒO faz:**
- Embeddings
- CÃ¡lculos estatÃ­sticos
- ETL
- Processamento de arquivos

---

### ServiÃ§o 2: RAG Service (Python/FastAPI)

**Responsabilidades:**
- IngestÃ£o de documentos (PDF, HTML, TXT)
- Chunking inteligente
- Embeddings (OpenAI/local)
- Vector search (pgvector)
- Reranking (quando necessÃ¡rio)
- CitaÃ§Ãµes e trechos

**Stack:**
- FastAPI
- LangChain/LlamaIndex
- OpenAI API / Sentence Transformers
- pgvector (Supabase)

**Arquitetura Interna:**
```python
# Pipeline 1: IngestÃ£o
class RAGIngestPipeline:
    async def process(self, file: UploadFile):
        # 1. Extrai texto
        text = await self.extract_text(file)
        
        # 2. Chunking com overlap
        chunks = self.chunk_text(
            text, 
            chunk_size=512, 
            overlap=50,
            strategy='semantic'  # ou 'fixed'
        )
        
        # 3. Embeddings
        embeddings = await self.generate_embeddings(chunks)
        
        # 4. Metadata
        metadata = {
            'source': file.filename,
            'tenant_id': get_tenant_id(),
            'data_ingestao': datetime.utcnow(),
            'tipo_documento': detect_document_type(file)
        }
        
        # 5. Armazena no pgvector
        await self.store_embeddings(chunks, embeddings, metadata)

# Pipeline 2: Consulta
class RAGQueryPipeline:
    async def query(self, question: str, filters: dict):
        # 1. Query embedding
        query_emb = await self.generate_embedding(question)
        
        # 2. Vector search + filtros
        results = await db.execute("""
            SELECT chunk, metadata, 
                   1 - (embedding <=> $1) as similarity
            FROM embeddings
            WHERE metadata->>'tenant_id' = $2
              AND metadata->>'tipo_documento' = $3
            ORDER BY embedding <=> $1
            LIMIT 20
        """, query_emb, filters['tenant_id'], filters['tipo'])
        
        # 3. Rerank (opcional - para top 5 final)
        if len(results) > 5:
            reranked = await self.rerank(question, results[:20])
            results = reranked[:5]
        
        # 4. Formata resposta com citaÃ§Ãµes
        return {
            'chunks': results,
            'sources': self.extract_sources(results)
        }
```

**Endpoints Internos:**
```python
POST   /ingest           # Upload documento
POST   /query            # Busca semÃ¢ntica
GET    /status/:doc_id   # Status ingestÃ£o
DELETE /document/:id     # Remove documento
POST   /reindex          # ReindexaÃ§Ã£o
```

---

### ServiÃ§o 3: ETL & Schedulers (Python)

**Responsabilidades:**
- Jobs CRON contÃ­nuos
- IngestÃ£o de APIs externas (SICONFI, IBGE, etc)
- NormalizaÃ§Ã£o/deduplicaÃ§Ã£o
- AtualizaÃ§Ã£o incremental
- Feature engineering (para analytics)

**Stack:**
- APScheduler ou Celery Beat
- Celery workers
- Redis/RabbitMQ (broker)
- SQLAlchemy

**Jobs Principais:**
```python
# Job 1: ImportaÃ§Ã£o diÃ¡ria SICONFI
@scheduler.scheduled_job('cron', hour=2, minute=0)
async def import_siconfi_daily():
    """Roda todo dia Ã s 2h"""
    
    # 1. Lista municÃ­pios que precisam atualizar
    municipios = await get_municipios_to_update()
    
    # 2. Publica jobs na fila
    for codigo_ibge in municipios:
        celery.send_task(
            'tasks.import_siconfi',
            args=[codigo_ibge],
            queue='high_priority'
        )

# Job 2: CÃ¡lculo de tendÃªncias semanais
@scheduler.scheduled_job('cron', day_of_week='sun', hour=4)
async def calculate_trends_weekly():
    """Roda todo domingo Ã s 4h"""
    
    municipios = await get_all_active_municipios()
    
    for codigo_ibge in municipios:
        # Calcula tendÃªncias dos Ãºltimos 12 meses
        await calculate_and_cache_trends(codigo_ibge, periods=12)

# Worker: ImportaÃ§Ã£o SICONFI
@celery.task(bind=True, max_retries=3)
def import_siconfi(self, codigo_ibge: str):
    try:
        # 1. Fetch API
        data = fetch_siconfi_api(codigo_ibge, year=2024)
        
        # 2. Normaliza
        normalized = normalize_siconfi_data(data)
        
        # 3. Deduplica
        deduplicated = remove_duplicates(normalized)
        
        # 4. Valida com Pydantic
        validated = [SiconfiRecord(**row) for row in deduplicated]
        
        # 5. Salva no banco
        await bulk_insert(validated)
        
        # 6. Registra fonte
        await register_data_source(
            nome='SICONFI RREO',
            codigo_ibge=codigo_ibge,
            data_coleta=datetime.utcnow()
        )
        
    except Exception as e:
        # Retry com backoff exponencial
        self.retry(exc=e, countdown=60 * (2 ** self.request.retries))
```

**ConfiguraÃ§Ã£o Celery:**
```python
# celery_config.py
from celery import Celery

celery = Celery(
    'etl_workers',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/1'
)

celery.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='America/Sao_Paulo',
    enable_utc=True,
    
    # Filas diferentes para prioridades
    task_routes={
        'tasks.import_siconfi': {'queue': 'high_priority'},
        'tasks.calculate_trends': {'queue': 'low_priority'},
    },
    
    # Retry policy
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    
    # Rate limiting
    task_annotations={
        'tasks.import_siconfi': {'rate_limit': '10/m'},
    }
)
```

---

### ServiÃ§o 4: Analytics/Modeling (Python)

**Responsabilidades:**
- CorrelaÃ§Ãµes
- TendÃªncias (linear, polinomial, sazonalidade)
- Outliers
- RegressÃµes
- Clustering
- Escreve resultados em tabelas materializadas

**Stack:**
- FastAPI
- NumPy, Pandas, SciPy
- statsmodels
- scikit-learn

```python
# service/analytics.py
from fastapi import FastAPI
import numpy as np
from scipy import stats
from statsmodels.tsa.seasonal import seasonal_decompose

app = FastAPI()

@app.post("/analytics/tendencias")
async def calcular_tendencias(request: TendenciaRequest):
    """
    Calcula tendÃªncias histÃ³ricas.
    
    NUNCA chamar do frontend - apenas via API Gateway.
    """
    codigo_ibge = request.codigo_ibge
    
    # 1. Busca histÃ³rico (Ãºltimos 3 anos)
    query = """
        SELECT exercicio, rcl, despesa_pessoal, percentual_dp_rcl
        FROM indicadores_fiscais
        WHERE codigo_ibge = $1
        ORDER BY exercicio
    """
    dados = await db.fetch(query, codigo_ibge)
    
    # 2. Prepara sÃ©ries temporais
    x = np.array([d['exercicio'] for d in dados])
    y_rcl = np.array([d['rcl'] for d in dados])
    y_dp = np.array([d['despesa_pessoal'] for d in dados])
    
    # 3. RegressÃ£o linear para RCL
    slope_rcl, intercept_rcl, r_value_rcl, p_value_rcl, _ = stats.linregress(
        x, y_rcl
    )
    
    # 4. Sazonalidade (se dados mensais)
    if len(dados) >= 24:  # MÃ­nimo 2 anos
        decomposition = seasonal_decompose(
            y_rcl, 
            model='additive', 
            period=12
        )
        sazonalidade = decomposition.seasonal.tolist()
    else:
        sazonalidade = None
    
    # 5. DetecÃ§Ã£o de outliers (Z-score)
    z_scores = np.abs(stats.zscore(y_dp))
    outliers = np.where(z_scores > 3)[0].tolist()
    
    # 6. ProjeÃ§Ã£o (prÃ³ximos 2 anos)
    anos_futuros = np.array([max(x) + 1, max(x) + 2])
    projecao_rcl = slope_rcl * anos_futuros + intercept_rcl
    
    # 7. Armazena em tabela materializada
    resultado = {
        'codigo_ibge': codigo_ibge,
        'tendencia_rcl': {
            'slope': float(slope_rcl),
            'r2': float(r_value_rcl ** 2),
            'direcao': 'crescente' if slope_rcl > 0 else 'decrescente'
        },
        'sazonalidade': sazonalidade,
        'outliers': outliers,
        'projecao': {
            str(int(ano)): float(valor) 
            for ano, valor in zip(anos_futuros, projecao_rcl)
        },
        'data_calculo': datetime.utcnow()
    }
    
    await db.execute("""
        INSERT INTO tendencias_cache (codigo_ibge, resultado, updated_at)
        VALUES ($1, $2, NOW())
        ON CONFLICT (codigo_ibge) DO UPDATE
        SET resultado = EXCLUDED.resultado, updated_at = NOW()
    """, codigo_ibge, json.dumps(resultado))
    
    return resultado

@app.post("/analytics/correlacoes")
async def calcular_correlacoes(request: CorrelacaoRequest):
    """
    Calcula matriz de correlaÃ§Ã£o entre indicadores.
    """
    codigos_ibge = request.codigos_ibge
    
    # Busca dados de mÃºltiplos municÃ­pios
    dados = await fetch_indicators_matrix(codigos_ibge)
    
    # Matriz de correlaÃ§Ã£o (Pearson)
    df = pd.DataFrame(dados)
    correlation_matrix = df.corr(method='pearson')
    
    # P-values para significÃ¢ncia
    p_values = calculate_pvalues(df)
    
    # Filtra apenas correlaÃ§Ãµes significativas (p < 0.05)
    significant = correlation_matrix.where(p_values < 0.05)
    
    return {
        'correlations': significant.to_dict(),
        'p_values': p_values.to_dict(),
        'sample_size': len(dados)
    }
```

---

### ServiÃ§o 5: Geo Service (PostGIS)

**Responsabilidades:**
- Queries geogrÃ¡ficas
- Radius search
- Nearest neighbors
- Polygons/boundaries
- Clustering espacial
- Geofencing

**Stack:**
- PostGIS (extension do PostgreSQL)
- GeoAlchemy2 (Python ORM)
- Shapely (geometrias)

```python
# service/geo.py
from geoalchemy2 import Geometry
from shapely.geometry import Point
from sqlalchemy import func

@app.get("/geo/municipios/proximos")
async def municipios_proximos(
    lat: float, 
    lng: float, 
    radius_km: float = 100
):
    """
    Encontra municÃ­pios num raio de X km.
    """
    
    # Point do usuÃ¡rio
    user_point = f'POINT({lng} {lat})'
    
    # Query PostGIS
    query = """
        SELECT 
            codigo_ibge,
            nome,
            ST_Distance(
                ST_GeogFromText($1),
                location::geography
            ) / 1000 as distancia_km
        FROM municipios
        WHERE ST_DWithin(
            location::geography,
            ST_GeogFromText($1),
            $2 * 1000  -- metros
        )
        ORDER BY distancia_km
    """
    
    result = await db.fetch(query, user_point, radius_km)
    return result

@app.post("/geo/cluster")
async def cluster_municipios(estados: list[str]):
    """
    Agrupa municÃ­pios geograficamente (k-means espacial).
    """
    
    # Busca coordenadas
    coords = await db.fetch("""
        SELECT codigo_ibge, ST_X(location) as lng, ST_Y(location) as lat
        FROM municipios
        WHERE uf = ANY($1)
    """, estados)
    
    # K-means clustering
    from sklearn.cluster import KMeans
    
    X = np.array([[c['lng'], c['lat']] for c in coords])
    kmeans = KMeans(n_clusters=5, random_state=42)
    labels = kmeans.fit_predict(X)
    
    # Adiciona cluster_id aos municÃ­pios
    result = [
        {**coords[i], 'cluster_id': int(labels[i])}
        for i in range(len(coords))
    ]
    
    return {
        'clusters': 5,
        'municipios': result,
        'centroids': kmeans.cluster_centers_.tolist()
    }
```

---

## ğŸ—„ï¸ ESTRUTURA DE TABELAS (PostgreSQL/Supabase)

### Tabelas Raw (Dados Brutos)
```sql
-- Dados direto das APIs
CREATE TABLE raw_siconfi_rreo (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  codigo_ibge TEXT NOT NULL,
  exercicio INTEGER NOT NULL,
  payload JSONB NOT NULL,  -- JSON completo da API
  data_coleta TIMESTAMPTZ DEFAULT NOW(),
  fonte TEXT NOT NULL
);

CREATE INDEX idx_raw_siconfi_codigo ON raw_siconfi_rreo(codigo_ibge, exercicio);
```

### Tabelas Staging (Normalizado)
```sql
-- Dados normalizados e validados
CREATE TABLE stg_indicadores_fiscais (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  codigo_ibge TEXT NOT NULL,
  exercicio INTEGER NOT NULL,
  rcl DECIMAL(15,2) NOT NULL CHECK (rcl > 0),
  despesa_pessoal DECIMAL(15,2) NOT NULL CHECK (despesa_pessoal >= 0),
  percentual_dp_rcl DECIMAL(5,2),
  data_processamento TIMESTAMPTZ DEFAULT NOW(),
  
  UNIQUE(codigo_ibge, exercicio)
);
```

### Tabelas Fato (Dimensionais)
```sql
-- Star schema para analytics
CREATE TABLE fct_indicadores_fiscais (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  codigo_ibge TEXT NOT NULL,
  dim_tempo_id INTEGER REFERENCES dim_tempo(id),
  rcl DECIMAL(15,2),
  despesa_pessoal DECIMAL(15,2),
  percentual_dp_rcl DECIMAL(5,2),
  status_lrf TEXT CHECK (status_lrf IN ('regular', 'alerta', 'critico'))
);

CREATE TABLE dim_tempo (
  id SERIAL PRIMARY KEY,
  exercicio INTEGER NOT NULL,
  bimestre INTEGER CHECK (bimestre BETWEEN 1 AND 6),
  ano INTEGER,
  trimestre INTEGER
);

CREATE TABLE dim_municipio (
  codigo_ibge TEXT PRIMARY KEY,
  nome TEXT NOT NULL,
  uf TEXT NOT NULL,
  regiao TEXT,
  populacao INTEGER,
  location GEOGRAPHY(POINT, 4326),  -- PostGIS
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Tabelas Agregadas (Cache/Performance)
```sql
-- PrÃ©-computadas para leitura rÃ¡pida
CREATE TABLE agg_tendencias (
  codigo_ibge TEXT PRIMARY KEY,
  tendencia_rcl JSONB,  -- {slope, r2, direcao}
  sazonalidade JSONB,
  outliers INTEGER[],
  projecao JSONB,
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE agg_comparacoes_regiao (
  regiao TEXT,
  exercicio INTEGER,
  media_rcl DECIMAL(15,2),
  media_dp_percentual DECIMAL(5,2),
  percentil_25 DECIMAL(15,2),
  percentil_75 DECIMAL(15,2),
  updated_at TIMESTAMPTZ,
  
  PRIMARY KEY (regiao, exercicio)
);

-- Materialized View para dashboards
CREATE MATERIALIZED VIEW mv_indicadores_latest AS
SELECT DISTINCT ON (codigo_ibge)
  codigo_ibge,
  exercicio,
  rcl,
  despesa_pessoal,
  percentual_dp_rcl,
  status_lrf
FROM fct_indicadores_fiscais
ORDER BY codigo_ibge, exercicio DESC;

CREATE UNIQUE INDEX ON mv_indicadores_latest(codigo_ibge);

-- Refresh agendado (CRON)
-- REFRESH MATERIALIZED VIEW CONCURRENTLY mv_indicadores_latest;
```

### Tabelas RAG (pgvector)
```sql
-- Embeddings para busca semÃ¢ntica
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE embeddings (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  chunk TEXT NOT NULL,
  embedding VECTOR(1536),  -- OpenAI text-embedding-3-small
  metadata JSONB NOT NULL,  -- {tenant_id, fonte, tipo_documento, data}
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Ãndice HNSW para busca rÃ¡pida
CREATE INDEX idx_embeddings_hnsw 
ON embeddings 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Ãndice GIN para filtros
CREATE INDEX idx_embeddings_metadata ON embeddings USING GIN(metadata);
```

---

## ğŸ”„ FILAS (OBRIGATÃ“RIO)

### Arquitetura de Filas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚  Redis Queue â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚ Python Workers â”‚
â”‚   (Node.js)  â”‚ publish â”‚   (BullMQ)   â”‚ consume â”‚   (Celery)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â†“
                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â”‚  PostgreSQL  â”‚
                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Filas por Prioridade

```python
# celery_config.py
CELERY_ROUTES = {
    # Alta prioridade (< 1 min)
    'tasks.calcular_indicador_urgente': {
        'queue': 'high_priority',
        'routing_key': 'high'
    },
    
    # MÃ©dia prioridade (< 5 min)
    'tasks.import_siconfi': {
        'queue': 'medium_priority',
        'routing_key': 'medium'
    },
    
    # Baixa prioridade (background)
    'tasks.calculate_trends': {
        'queue': 'low_priority',
        'routing_key': 'low'
    },
    
    # Muito longo (horas)
    'tasks.full_etl_all_municipios': {
        'queue': 'batch_jobs',
        'routing_key': 'batch'
    }
}
```

### Exemplo Completo: Fluxo com Fila

```typescript
// Node.js - API Gateway
import Bull from 'bullmq';

const analysisQueue = new Bull('fiscal-analysis', {
  connection: { host: 'localhost', port: 6379 }
});

app.post('/api/municipios/:id/analisar-completa', async (req, res) => {
  const { id } = req.params;
  
  // Adiciona job na fila
  const job = await analysisQueue.add('analise-completa', {
    codigoIbge: id,
    userId: req.user.id,
    timestamp: new Date()
  }, {
    attempts: 3,  // Retry 3 vezes
    backoff: {
      type: 'exponential',
      delay: 5000
    },
    removeOnComplete: 100,  // Manter Ãºltimos 100 jobs
    removeOnFail: 500
  });
  
  // Responde imediatamente com job_id
  res.json({
    jobId: job.id,
    status: 'queued',
    estimatedTime: '45s',
    statusUrl: `/api/jobs/${job.id}`
  });
});

// Endpoint para checar status
app.get('/api/jobs/:id', async (req, res) => {
  const job = await analysisQueue.getJob(req.params.id);
  
  if (!job) {
    return res.status(404).json({ error: 'Job nÃ£o encontrado' });
  }
  
  const state = await job.getState();
  const progress = job.progress;
  
  res.json({
    id: job.id,
    status: state,  // 'completed', 'failed', 'active', 'waiting'
    progress: progress,
    result: state === 'completed' ? job.returnvalue : null,
    failedReason: state === 'failed' ? job.failedReason : null
  });
});
```

```python
# Python - Worker
from celery import Celery, Task

celery = Celery('workers')

class CallbackTask(Task):
    """Task com callback de progresso"""
    
    def on_success(self, retval, task_id, args, kwargs):
        # Notifica via websocket ou webhook
        notify_completion(task_id, retval)
    
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        # Loga erro e notifica
        log_error(task_id, exc)

@celery.task(base=CallbackTask, bind=True)
def analise_completa(self, codigo_ibge: str, user_id: str):
    """
    AnÃ¡lise fiscal completa - pode demorar 30-60s.
    
    NUNCA executar sÃ­ncrono na API pÃºblica.
    """
    
    # 1. Coleta dados (10%)
    self.update_state(state='PROGRESS', meta={'progress': 10, 'step': 'Coletando dados'})
    rreo = fetch_rreo_api(codigo_ibge)
    rgf = fetch_rgf_api(codigo_ibge)
    
    # 2. Calcula indicadores (30%)
    self.update_state(state='PROGRESS', meta={'progress': 30, 'step': 'Calculando indicadores'})
    indicadores = calcular_indicadores_lrf(rreo, rgf)
    
    # 3. AnÃ¡lise estatÃ­stica (60%)
    self.update_state(state='PROGRESS', meta={'progress': 60, 'step': 'AnÃ¡lise estatÃ­stica'})
    tendencias = calcular_tendencias(codigo_ibge, periods=24)
    correlacoes = calcular_correlacoes_regionais(codigo_ibge)
    
    # 4. ComparaÃ§Ã£o com pares (80%)
    self.update_state(state='PROGRESS', meta={'progress': 80, 'step': 'Comparando com pares'})
    peers = find_similar_municipios(codigo_ibge)
    comparacao = compare_with_peers(indicadores, peers)
    
    # 5. Salva resultado (100%)
    self.update_state(state='PROGRESS', meta={'progress': 100, 'step': 'Finalizando'})
    resultado_id = await save_analysis_result({
        'codigo_ibge': codigo_ibge,
        'user_id': user_id,
        'indicadores': indicadores,
        'tendencias': tendencias,
        'correlacoes': correlacoes,
        'comparacao': comparacao,
        'timestamp': datetime.utcnow()
    })
    
    return {
        'resultado_id': resultado_id,
        'codigo_ibge': codigo_ibge,
        'status': 'completed'
    }
```

---

## ğŸ“Š REGRAS DE OURO - PERFORMANCE & ARQUITETURA

### 1. Tudo > 300-800ms = AssÃ­ncrono (OBRIGATÃ“RIO)

```typescript
// âŒ NUNCA fazer sÃ­ncrono se demorar > 300ms
app.get('/calcular-tendencias', async (req, res) => {
  const result = await heavyCalculation();  // 5 segundos âŒ INACEITÃVEL
  res.json(result);
});

// âœ… Usar fila + job assÃ­ncrono
app.post('/calcular-tendencias', async (req, res) => {
  const job = await queue.add('tendencias', req.body);
  res.json({ 
    jobId: job.id, 
    statusUrl: `/jobs/${job.id}`,
    estimatedTime: '45s'
  });
});

// Cliente pode pooling no status
app.get('/jobs/:id', async (req, res) => {
  const job = await queue.getJob(req.params.id);
  res.json({
    status: job.state,  // 'completed', 'active', 'failed'
    progress: job.progress,
    result: job.returnvalue
  });
});
```

### 2. API PÃºblica NUNCA Calcula ao Vivo

```sql
-- âŒ NUNCA na API pÃºblica (milhÃµes de linhas, 5-10s)
SELECT 
  AVG(percentual_dp_rcl) as media,
  STDDEV(percentual_dp_rcl) as desvio,
  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY percentual_dp_rcl) as mediana
FROM indicadores_fiscais
WHERE regiao = 'Sudeste'
  AND exercicio >= 2020
GROUP BY exercicio, bimestre;  

-- âœ… PrÃ©-computar em job noturno (Python worker)
-- API apenas lÃª tabela agregada (< 10ms)
SELECT * FROM agg_estatisticas_regiao
WHERE regiao = 'Sudeste' AND exercicio = 2024;
```

### 3. Estrutura de Tabelas: 4 Camadas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: raw_* (Dados Brutos)                       â”‚
â”‚ â€¢ JSONB direto da API                               â”‚
â”‚ â€¢ ImutÃ¡vel, append-only                             â”‚
â”‚ â€¢ RetenÃ§Ã£o: 90 dias                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ ETL Pipeline (Python)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: stg_* (Staging - Normalizado)             â”‚
â”‚ â€¢ Dados validados (Pydantic)                        â”‚
â”‚ â€¢ NormalizaÃ§Ã£o, deduplicaÃ§Ã£o                        â”‚
â”‚ â€¢ Constraints, foreign keys                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ Data Modeling
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: fct_* + dim_* (Star Schema)               â”‚
â”‚ â€¢ Fatos: indicadores, mÃ©tricas, eventos             â”‚
â”‚ â€¢ DimensÃµes: tempo, municÃ­pio, categoria            â”‚
â”‚ â€¢ Queries analÃ­ticas otimizadas                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ AgregaÃ§Ã£o (Python CRON)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: agg_* + mv_* (Agregados/Views)            â”‚
â”‚ â€¢ PrÃ©-computado para consumo rÃ¡pido                 â”‚
â”‚ â€¢ Materialized views (refresh agendado)             â”‚
â”‚ â€¢ API pÃºblica LÃŠ APENAS DAQUI                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemplo Completo:**
```sql
-- Layer 1: Raw (imutÃ¡vel)
CREATE TABLE raw_siconfi_rreo (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  codigo_ibge TEXT NOT NULL,
  exercicio INTEGER NOT NULL,
  payload JSONB NOT NULL,  -- JSON completo da API
  data_coleta TIMESTAMPTZ DEFAULT NOW(),
  fonte TEXT NOT NULL,
  
  -- Particionamento por ano
  PARTITION BY RANGE (exercicio)
);

-- Layer 2: Staging (normalizado)
CREATE TABLE stg_indicadores_fiscais (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  codigo_ibge TEXT NOT NULL,
  exercicio INTEGER NOT NULL,
  bimestre INTEGER CHECK (bimestre BETWEEN 1 AND 6),
  rcl DECIMAL(15,2) NOT NULL CHECK (rcl > 0),
  despesa_pessoal DECIMAL(15,2) NOT NULL CHECK (despesa_pessoal >= 0),
  data_processamento TIMESTAMPTZ DEFAULT NOW(),
  
  UNIQUE(codigo_ibge, exercicio, bimestre)
);

-- Layer 3: Fato + DimensÃ£o (star schema)
CREATE TABLE fct_indicadores_fiscais (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  codigo_ibge TEXT REFERENCES dim_municipio(codigo_ibge),
  dim_tempo_id INTEGER REFERENCES dim_tempo(id),
  rcl DECIMAL(15,2),
  despesa_pessoal DECIMAL(15,2),
  percentual_dp_rcl DECIMAL(5,2),
  status_lrf TEXT CHECK (status_lrf IN ('regular', 'alerta', 'critico')),
  
  -- Ãndices para queries comuns
  INDEX idx_fct_municipio (codigo_ibge, dim_tempo_id DESC),
  INDEX idx_fct_status (status_lrf, dim_tempo_id DESC)
);

CREATE TABLE dim_tempo (
  id SERIAL PRIMARY KEY,
  exercicio INTEGER NOT NULL,
  bimestre INTEGER,
  ano INTEGER,
  trimestre INTEGER,
  semestre INTEGER,
  UNIQUE(exercicio, bimestre)
);

CREATE TABLE dim_municipio (
  codigo_ibge TEXT PRIMARY KEY,
  nome TEXT NOT NULL,
  uf TEXT NOT NULL,
  regiao TEXT,
  populacao INTEGER,
  location GEOGRAPHY(POINT, 4326),  -- PostGIS
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Layer 4: Agregados (leitura rÃ¡pida)
CREATE TABLE agg_estatisticas_regiao (
  regiao TEXT,
  exercicio INTEGER,
  bimestre INTEGER,
  
  -- EstatÃ­sticas prÃ©-computadas
  media_rcl DECIMAL(15,2),
  media_dp_percentual DECIMAL(5,2),
  desvio_padrao DECIMAL(5,2),
  percentil_25 DECIMAL(5,2),
  percentil_50 DECIMAL(5,2),
  percentil_75 DECIMAL(5,2),
  total_municipios INTEGER,
  
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  
  PRIMARY KEY (regiao, exercicio, bimestre)
);

-- Materialized View (refresh diÃ¡rio via CRON)
CREATE MATERIALIZED VIEW mv_indicadores_latest AS
SELECT DISTINCT ON (codigo_ibge)
  codigo_ibge,
  exercicio,
  bimestre,
  rcl,
  despesa_pessoal,
  percentual_dp_rcl,
  status_lrf
FROM fct_indicadores_fiscais
ORDER BY codigo_ibge, exercicio DESC, bimestre DESC;

CREATE UNIQUE INDEX ON mv_indicadores_latest(codigo_ibge);

-- Python CRON (todo dia 2h)
-- REFRESH MATERIALIZED VIEW CONCURRENTLY mv_indicadores_latest;
```

### 4. PrÃ©-Compute Tudo Que For PossÃ­vel

```sql
-- âŒ NUNCA calcular ao vivo na API
SELECT 
  AVG(percentual_dp_rcl) as media,
  STDDEV(percentual_dp_rcl) as desvio
FROM indicadores_fiscais
WHERE regiao = 'Sudeste'
GROUP BY exercicio;  -- MilhÃµes de linhas, lento!

-- âœ… PrÃ©-computar em job noturno
CREATE TABLE agg_estatisticas_regiao (
  regiao TEXT,
  exercicio INTEGER,
  media_dp_rcl DECIMAL(5,2),
  desvio_dp_rcl DECIMAL(5,2),
  updated_at TIMESTAMPTZ,
  PRIMARY KEY (regiao, exercicio)
);

-- Job CRON popula essa tabela
-- API apenas lÃª (rÃ¡pido!)
```

### 2. Tudo > 300-800ms = AssÃ­ncrono

```typescript
// âŒ NUNCA fazer sÃ­ncrono se demorar
app.get('/calcular-tendencias', async (req, res) => {
  const result = await heavyCalculation();  // 5 segundos âŒ
  res.json(result);
});

// âœ… Usar fila
app.post('/calcular-tendencias', async (req, res) => {
  const job = await queue.add('tendencias', req.body);
  res.json({ jobId: job.id, statusUrl: `/jobs/${job.id}` });
});
```

### 3. Estrutura de Tabelas: Raw â†’ Staging â†’ Fato â†’ Agregada

```
raw_*        â†’ Dados brutos da API (JSONB)
stg_*        â†’ Normalizado e validado
fct_*        â†’ Star schema (dimensional)
agg_*        â†’ PrÃ©-computado para consumo rÃ¡pido
mv_*         â†’ Materialized views (refresh agendado)
```

### 5. CRON Centralizado (OBRIGATÃ“RIO)

```python
# âŒ NUNCA espalhar CRON em todo lugar
# crontab no servidor 1, 2, 3... = caos

# âœ… Scheduler centralizado (Python)
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

scheduler = AsyncIOScheduler(timezone='America/Sao_Paulo')

# Job 1: ImportaÃ§Ã£o diÃ¡ria SICONFI (2h da manhÃ£)
@scheduler.scheduled_job(CronTrigger(hour=2, minute=0))
async def import_siconfi_daily():
    """
    Importa RREO de todos os municÃ­pios ativos.
    
    ExecuÃ§Ã£o: Todo dia 2h
    DuraÃ§Ã£o: ~45min (5570 municÃ­pios)
    """
    municipios = await get_active_municipios()
    
    # Publica jobs na fila (nÃ£o processa sÃ­ncrono)
    for codigo_ibge in municipios:
        await queue.add('import_siconfi', {
            'codigo_ibge': codigo_ibge,
            'exercicio': datetime.now().year,
            'prioridade': 'normal'
        })
    
    logger.info(f"Agendado import para {len(municipios)} municÃ­pios")

# Job 2: Refresh de Materialized Views (3h da manhÃ£)
@scheduler.scheduled_job(CronTrigger(hour=3, minute=0))
async def refresh_materialized_views():
    """
    Atualiza todas as materialized views.
    
    ExecuÃ§Ã£o: Todo dia 3h
    DuraÃ§Ã£o: ~10min
    """
    await db.execute("REFRESH MATERIALIZED VIEW CONCURRENTLY mv_indicadores_latest")
    await db.execute("REFRESH MATERIALIZED VIEW CONCURRENTLY mv_tendencias_regiao")
    await db.execute("REFRESH MATERIALIZED VIEW CONCURRENTLY mv_comparacoes_peers")

# Job 3: CÃ¡lculo de tendÃªncias (domingo 4h)
@scheduler.scheduled_job(CronTrigger(day_of_week='sun', hour=4))
async def calculate_trends_weekly():
    """
    Calcula tendÃªncias histÃ³ricas (Ãºltimos 24 meses).
    
    ExecuÃ§Ã£o: Todo domingo 4h
    DuraÃ§Ã£o: ~2h (processamento pesado)
    """
    municipios = await get_all_municipios()
    
    for codigo_ibge in municipios:
        await queue.add('calculate_trends', {
            'codigo_ibge': codigo_ibge,
            'periods': 24,
            'prioridade': 'baixa'
        })

# Job 4: Limpeza de dados antigos (1Âº dia do mÃªs, 1h)
@scheduler.scheduled_job(CronTrigger(day=1, hour=1))
async def cleanup_old_data():
    """
    Remove dados raw > 90 dias.
    
    ExecuÃ§Ã£o: 1Âº dia do mÃªs, 1h
    """
    cutoff_date = datetime.now() - timedelta(days=90)
    
    deleted = await db.execute("""
        DELETE FROM raw_siconfi_rreo
        WHERE data_coleta < $1
    """, cutoff_date)
    
    logger.info(f"Removidos {deleted} registros antigos")

# Job 5: Backup incremental (todo dia 5h)
@scheduler.scheduled_job(CronTrigger(hour=5, minute=0))
async def backup_incremental():
    """
    Backup incremental do banco.
    """
    await run_backup_command()

# Inicia scheduler
scheduler.start()
```

### 6. Ãndices Inteligentes (CRÃTICO)

```sql
-- âœ… Ãndice composto para queries comuns
CREATE INDEX idx_indicadores_lookup 
ON fct_indicadores_fiscais(codigo_ibge, exercicio DESC);

-- âœ… Partial index (apenas dados recentes = menor, mais rÃ¡pido)
CREATE INDEX idx_indicadores_recent 
ON fct_indicadores_fiscais(codigo_ibge, exercicio) 
WHERE exercicio >= 2020;

-- âœ… Index-only scan (covering index)
CREATE INDEX idx_indicadores_status_covering 
ON fct_indicadores_fiscais(codigo_ibge, exercicio, status_lrf)
INCLUDE (percentual_dp_rcl);

-- âœ… GiST para geo queries (PostGIS)
CREATE INDEX idx_municipios_location 
ON dim_municipio USING GIST(location);

-- âœ… HNSW para vector search (pgvector)
CREATE INDEX idx_embeddings_vector 
ON embeddings USING hnsw(embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- âœ… GIN para JSONB
CREATE INDEX idx_metadata_gin 
ON embeddings USING GIN(metadata);

-- âœ… B-tree para filtros comuns
CREATE INDEX idx_indicadores_status 
ON fct_indicadores_fiscais(status_lrf, exercicio DESC);

-- âŒ NUNCA criar Ã­ndice em:
-- - Tabelas pequenas (< 1000 linhas)
-- - Colunas com baixa cardinalidade e sem filtro (ex: boolean sem WHERE)
-- - Colunas que mudam muito (alto write churn)
```

---

```sql
-- Ãndice composto para queries comuns
CREATE INDEX idx_indicadores_lookup 
ON fct_indicadores_fiscais(codigo_ibge, exercicio DESC);

-- Partial index (apenas dados recentes)
CREATE INDEX idx_indicadores_recent 
ON fct_indicadores_fiscais(codigo_ibge) 
WHERE exercicio >= 2020;

-- GiST para geo queries
CREATE INDEX idx_municipios_location 
ON dim_municipio USING GIST(location);

-- HNSW para vector search
CREATE INDEX idx_embeddings_vector 
ON embeddings USING hnsw(embedding vector_cosine_ops);
```

---

## ğŸ” SEGURANÃ‡A & COMPLIANCE (ISO 27001/27701)

### Logging Estruturado

```typescript
// Winston + request_id
import winston from 'winston';

const logger = winston.createLogger({
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.File({ 
      filename: 'logs/api.log',
      maxsize: 10485760,  // 10MB
      maxFiles: 30
    })
  ]
});

// Middleware de logging
app.use((req, res, next) => {
  req.id = uuidv4();  // request_id Ãºnico
  
  logger.info('incoming_request', {
    request_id: req.id,
    method: req.method,
    url: req.url,
    user_id: req.user?.id,
    tenant_id: req.tenant?.id,
    ip: req.ip,
    user_agent: req.get('user-agent')
  });
  
  next();
});
```

### Auditoria

```sql
-- Tabela de auditoria
CREATE TABLE audit_log (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  
  -- Quem
  user_id UUID,
  tenant_id UUID,
  
  -- O quÃª
  action TEXT NOT NULL,  -- 'CREATE', 'UPDATE', 'DELETE', 'READ'
  resource_type TEXT NOT NULL,
  resource_id UUID,
  
  -- Como
  changes JSONB,  -- before/after
  
  -- Quando/Onde
  timestamp TIMESTAMPTZ DEFAULT NOW(),
  ip_address INET,
  user_agent TEXT,
  request_id UUID,
  
  -- Metadados
  metadata JSONB
);

-- Ãndices
CREATE INDEX idx_audit_user ON audit_log(user_id, timestamp DESC);
CREATE INDEX idx_audit_tenant ON audit_log(tenant_id, timestamp DESC);
CREATE INDEX idx_audit_resource ON audit_log(resource_type, resource_id);
CREATE INDEX idx_audit_timestamp ON audit_log(timestamp DESC);
```

---

## ğŸ¤ GESTÃƒO DE VOZ (CRÃTICO)

### ConfiguraÃ§Ã£o OpenAI TTS (gpt-4o-mini-tts)

**LocalizaÃ§Ã£o:** `src/config/voice-config.ts` (iconsai-production)

```typescript
// SEMPRE usar estes presets conforme mÃ³dulo
export const VOICE_PRESETS = {
  friendly_assistant: {
    model: 'gpt-4o-mini-tts',
    voice: 'marin',
    speed: 1.0,
    instructions: `
      Voice Affect: Warm, friendly, naturally conversational.
      Tone: Approachable, like a knowledgeable friend.
      Language: Brazilian Portuguese with natural intonation.
      Avoid: Robotic monotone, rushed speech.
    `
  },
  calm_health: {
    voice: 'cedar',
    speed: 0.95,
    instructions: `
      Voice Affect: Calm, reassuring, empathetic.
      Tone: Professional yet warm healthcare provider.
      Language: Brazilian Portuguese.
    `
  },
  creative_ideas: {
    voice: 'nova',
    speed: 1.05,
    instructions: `
      Voice Affect: Energetic, inspiring, creative.
      Tone: Enthusiastic, sparking excitement.
    `
  }
};
```

### ParÃ¢metros ElevenLabs (quando usado)

```json
{
  "stability": 0.45,
  "similarity_boost": 0.75,
  "style_exaggeration": 0.15,
  "speed": 1.0,
  "use_speaker_boost": true
}
```

### Vozes OpenAI Recomendadas

| MÃ³dulo | Voz | CaracterÃ­sticas |
|--------|-----|-----------------|
| Home/Help | `marin` | Calorosa, natural |
| SaÃºde | `cedar` | Calma, reconfortante |
| Ideias | `nova` | EnergÃ©tica, engajada |
| Mundo/Info | `sage` | SÃ¡bia, educativa |

---

## ğŸ“Š RASTREAMENTO DE FONTES DE DADOS

### Estrutura da Tabela (OBRIGATÃ“RIA em todos os projetos)

```sql
CREATE TABLE fontes_dados (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  
  -- IdentificaÃ§Ã£o
  nome TEXT NOT NULL,                  -- Ex: "SICONFI - RREO"
  categoria TEXT NOT NULL,             -- Ex: "fiscal", "geografico", "economico"
  
  -- Origem
  fonte_primaria TEXT NOT NULL,        -- Ex: "Tesouro Nacional"
  url TEXT NOT NULL,                   -- URL da API/fonte
  documentacao_url TEXT,               -- URL da documentaÃ§Ã£o
  
  -- Rastreamento
  data_primeira_coleta TIMESTAMPTZ NOT NULL,
  data_ultima_atualizacao TIMESTAMPTZ,
  periodicidade TEXT,                  -- "mensal", "bimestral", "anual"
  
  -- Metadados
  formato TEXT,                        -- "JSON", "CSV", "XML"
  autenticacao_requerida BOOLEAN DEFAULT false,
  api_key_necessaria BOOLEAN DEFAULT false,
  
  -- Qualidade
  confiabilidade TEXT,                 -- "alta", "media", "baixa"
  cobertura_temporal TEXT,             -- Ex: "2015-presente"
  observacoes TEXT,
  
  -- Audit
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Ãndices
CREATE INDEX idx_fontes_categoria ON fontes_dados(categoria);
CREATE INDEX idx_fontes_periodicidade ON fontes_dados(periodicidade);
```

### Exemplo de Registro

```sql
INSERT INTO fontes_dados (
  nome,
  categoria,
  fonte_primaria,
  url,
  documentacao_url,
  data_primeira_coleta,
  periodicidade,
  formato,
  confiabilidade,
  cobertura_temporal
) VALUES (
  'SICONFI - RelatÃ³rio Resumido ExecuÃ§Ã£o OrÃ§amentÃ¡ria',
  'fiscal',
  'Tesouro Nacional',
  'https://apidatalake.tesouro.gov.br/ords/siconfi/tt/rreo',
  'https://siconfi.tesouro.gov.br/siconfi/pages/public/consulta_finbra/finbra_list.jsf',
  '2026-01-15',
  'bimestral',
  'JSON',
  'alta',
  '2015-presente'
);
```

---

## ğŸ”§ COMANDOS PRINCIPAIS

### iconsai-production
```bash
npm run dev              # Dev local
npm run build            # Build produÃ§Ã£o
npm run lint             # ESLint check
npm run preview          # Preview build
npm run validate         # lint + pre-deploy + build
```

### orcamento-fiscal-municipios
```bash
npm run dev              # Frontend dev
npm run build            # TypeScript compile + Vite build
npm run lint             # ESLint check

# Python scripts (backend)
python scripts/siconfi_rreo_import.py          # Importar RREO
python scripts/popular_indicadores_fiscais.py  # Calcular indicadores
python scripts/aplicar_migration_*.py          # Migrations
```

### scraping-hub
```bash
# Backend Python
uvicorn api.main:app --reload     # Dev local
pytest                            # Run tests
pytest --cov                      # Com coverage

# Frontend (se houver)
cd frontend && npm run dev
```

---

## ğŸ—ï¸ PADRÃ•ES DE CÃ“DIGO

### TypeScript (Frontend)

```typescript
// âœ… DO: Type safety completo
interface FiscalIndicator {
  codigo_ibge: string;
  rcl: number;
  despesa_pessoal: number;
  percentual_dp_rcl: number;
  status_lrf: 'regular' | 'alerta' | 'critico';
}

// âœ… DO: ValidaÃ§Ã£o com Zod
import { z } from 'zod';

const FiscalIndicatorSchema = z.object({
  codigo_ibge: z.string().regex(/^\d{7}$/),
  rcl: z.number().positive(),
  despesa_pessoal: z.number().nonnegative(),
  percentual_dp_rcl: z.number().min(0).max(100),
  status_lrf: z.enum(['regular', 'alerta', 'critico'])
});

// âœ… DO: Async/await para I/O
async function fetchIndicators(codigoIbge: string): Promise<FiscalIndicator> {
  const { data, error } = await supabase
    .from('indicadores_fiscais')
    .select('*')
    .eq('codigo_ibge', codigoIbge)
    .single();
  
  if (error) throw new AppError(error.message, 500);
  return FiscalIndicatorSchema.parse(data);
}

// âŒ DON'T: CÃ¡lculos complexos no frontend
const percentual = (despesa / rcl) * 100; // âŒ Fazer no backend Python

// âœ… DO: Chamar endpoint que calcula
const { percentual } = await api.calcularPercentualDpRcl(codigoIbge);
```

### Python (Backend)

```python
# âœ… DO: Type hints obrigatÃ³rios
from typing import List, Optional
from pydantic import BaseModel, Field
from datetime import datetime

class FiscalIndicator(BaseModel):
    codigo_ibge: str = Field(..., regex=r'^\d{7}$')
    rcl: float = Field(..., gt=0)
    despesa_pessoal: float = Field(..., ge=0)
    percentual_dp_rcl: float = Field(..., ge=0, le=100)
    status_lrf: Literal['regular', 'alerta', 'critico']
    
    class Config:
        frozen = True  # ImutÃ¡vel

# âœ… DO: Async para I/O
async def fetch_indicators(codigo_ibge: str) -> FiscalIndicator:
    """
    Busca indicadores fiscais de um municÃ­pio.
    
    Args:
        codigo_ibge: CÃ³digo IBGE de 7 dÃ­gitos
        
    Returns:
        FiscalIndicator com dados validados
        
    Raises:
        ValueError: Se cÃ³digo IBGE invÃ¡lido
        HTTPException: Se municÃ­pio nÃ£o encontrado
    """
    query = "SELECT * FROM indicadores_fiscais WHERE codigo_ibge = $1"
    row = await db.fetchrow(query, codigo_ibge)
    
    if not row:
        raise HTTPException(404, "MunicÃ­pio nÃ£o encontrado")
    
    return FiscalIndicator(**dict(row))

# âœ… DO: CÃ¡lculos complexos em Python
def calcular_percentual_dp_rcl(
    despesa_pessoal: float,
    rcl: float,
    aplicar_limite_prudencial: bool = False
) -> float:
    """
    Calcula percentual de Despesa com Pessoal sobre RCL.
    
    Conforme LRF (Lei Complementar 101/2000):
    - Limite total: 60% RCL (municÃ­pio)
    - Limite prudencial: 57% RCL (95% do limite)
    - Limite de alerta: 54% RCL (90% do limite)
    
    Args:
        despesa_pessoal: Total da despesa com pessoal
        rcl: Receita Corrente LÃ­quida
        aplicar_limite_prudencial: Se deve usar limite prudencial
        
    Returns:
        Percentual calculado (0-100)
    """
    if rcl <= 0:
        raise ValueError("RCL deve ser positiva")
    
    percentual = (despesa_pessoal / rcl) * 100
    
    # Arredondar para 2 casas decimais
    return round(percentual, 2)

# âŒ DON'T: SQL direto
result = db.execute(f"SELECT * FROM users WHERE id = {user_id}")  # SQL Injection!

# âœ… DO: Prepared statements
result = await db.fetchrow("SELECT * FROM users WHERE id = $1", user_id)
```

---

## ğŸ§ª TESTES

### Frontend (Vitest)

```typescript
// src/__tests__/calculos.test.ts
import { describe, it, expect } from 'vitest';
import { calcularStatus } from '../utils/fiscais';

describe('CÃ¡lculos Fiscais', () => {
  it('deve classificar como regular quando < 90%', () => {
    const status = calcularStatus(45.5); // 45.5% de DP/RCL
    expect(status).toBe('regular');
  });
  
  it('deve classificar como alerta quando >= 90% e < 95%', () => {
    const status = calcularStatus(91.2);
    expect(status).toBe('alerta');
  });
  
  it('deve classificar como crÃ­tico quando >= 95%', () => {
    const status = calcularStatus(97.8);
    expect(status).toBe('critico');
  });
});
```

### Backend (pytest)

```python
# tests/test_fiscal_calculations.py
import pytest
from decimal import Decimal
from services.fiscal import calcular_percentual_dp_rcl

def test_calculo_percentual_dp_rcl_basico():
    """Testa cÃ¡lculo bÃ¡sico do percentual DP/RCL"""
    percentual = calcular_percentual_dp_rcl(
        despesa_pessoal=100_000,
        rcl=200_000
    )
    assert percentual == 50.0

def test_calculo_com_rcl_zero_deve_falhar():
    """Testa que RCL zero levanta ValueError"""
    with pytest.raises(ValueError, match="RCL deve ser positiva"):
        calcular_percentual_dp_rcl(
            despesa_pessoal=100_000,
            rcl=0
        )

@pytest.mark.asyncio
async def test_fetch_indicators_municipio_inexistente():
    """Testa busca de municÃ­pio inexistente"""
    with pytest.raises(HTTPException) as exc_info:
        await fetch_indicators("9999999")
    
    assert exc_info.value.status_code == 404
```

---

## ğŸ“š DOCUMENTAÃ‡ÃƒO ESSENCIAL

### Locais de DocumentaÃ§Ã£o por Projeto

#### orcamento-fiscal-municipios
- `docs/FONTES_DADOS.md` â†’ Todas as fontes de dados usadas
- `docs/VOICE_HUMANIZATION_GUIDE.md` â†’ Guia completo de TTS
- `docs/AUDITORIA_*.md` â†’ Auditorias do sistema
- `docs/api-contracts/` â†’ Contratos de API

#### iconsai-production
- `docs/PWA_SPECIFICATION.md` â†’ EspecificaÃ§Ã£o do PWA
- `docs/PRE-DEPLOY-CHECKLIST.md` â†’ Checklist antes de deploy

#### scraping-hub
- `README.md` â†’ Setup e configuraÃ§Ã£o
- `tests/` â†’ Exemplos de uso

---

## ğŸš€ WORKFLOW DE DESENVOLVIMENTO

### 1. Entendimento do Requisito
```markdown
Antes de QUALQUER cÃ³digo:

1. âœ… Ler o requisito completamente
2. âœ… Criar questionÃ¡rio de validaÃ§Ã£o:
   - O que foi compreendido?
   - Quais componentes serÃ£o afetados?
   - Existem cÃ¡lculos envolvidos? (Backend!)
   - Precisa TTS? (Qual mÃ³dulo?)
   - Fontes de dados? (Registrar!)
3. âœ… Aguardar confirmaÃ§Ã£o do usuÃ¡rio
4. âœ… SÃ“ ENTÃƒO comeÃ§ar a implementar
```

### 2. ImplementaÃ§Ã£o
```markdown
Durante implementaÃ§Ã£o:

1. âœ… Seguir EXATAMENTE o que foi pedido
2. âœ… NÃƒO mudar cÃ³digo nÃ£o relacionado
3. âœ… CÃ¡lculos matemÃ¡ticos â†’ Python backend
4. âœ… Dados â†’ vir de API/DB, NUNCA hardcode
5. âœ… TTS â†’ usar presets, nunca browser voice
6. âœ… Registrar fontes de dados
```

### 3. ValidaÃ§Ã£o
```markdown
Antes de entregar:

1. âœ… CÃ³digo compila/roda?
2. âœ… Testes passam?
3. âœ… Lint OK?
4. âœ… Fontes registradas?
5. âœ… TTS configurado (se aplicÃ¡vel)?
6. âœ… DocumentaÃ§Ã£o atualizada?
```

---

## ğŸ” SEGURANÃ‡A

### VariÃ¡veis de Ambiente

```bash
# NUNCA commitar secrets
# SEMPRE usar .env e .env.example

# .env (gitignored)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=xxx
OPENAI_API_KEY=sk-xxx
ELEVENLABS_API_KEY=xxx
DATABASE_URL=postgresql://xxx

# .env.example (versionado)
SUPABASE_URL=
SUPABASE_ANON_KEY=
OPENAI_API_KEY=
ELEVENLABS_API_KEY=
DATABASE_URL=
```

### Input Validation

```typescript
// âœ… SEMPRE validar input do usuÃ¡rio
import { z } from 'zod';

const UserInputSchema = z.object({
  codigoIbge: z.string().regex(/^\d{7}$/, 'CÃ³digo IBGE invÃ¡lido'),
  exercicio: z.number().int().min(2015).max(new Date().getFullYear())
});

async function handleUserInput(input: unknown) {
  try {
    const validated = UserInputSchema.parse(input);
    // Usar validated, nÃ£o input diretamente
  } catch (error) {
    if (error instanceof z.ZodError) {
      throw new ValidationError(error.errors);
    }
  }
}
```

---

## ğŸ“– GLOSSÃRIO FISCAL (orcamento-fiscal)

- **RCL**: Receita Corrente LÃ­quida
- **DP**: Despesa com Pessoal
- **LRF**: Lei de Responsabilidade Fiscal (LC 101/2000)
- **RREO**: RelatÃ³rio Resumido da ExecuÃ§Ã£o OrÃ§amentÃ¡ria
- **RGF**: RelatÃ³rio de GestÃ£o Fiscal
- **DCA**: Demonstrativo das Contas Anuais
- **SICONFI**: Sistema de InformaÃ§Ãµes ContÃ¡beis e Fiscais
- **IBGE**: Instituto Brasileiro de Geografia e EstatÃ­stica
- **Limite Prudencial**: 95% do limite total (57% para municÃ­pios)
- **Limite de Alerta**: 90% do limite total (54% para municÃ­pios)

---

## âš ï¸ PROBLEMAS CONHECIDOS

### scraping-hub (PROBLEMÃTICO)
- Quebra frequente de scrapers (sites mudam)
- Falta de retry logic robusto
- Logs insuficientes para debug
- Necessita refactoring em services/

### iconsai-production
- MÃºltiplos mÃ³dulos com lÃ³gica duplicada
- Necessita consolidaÃ§Ã£o de componentes
- Performance de renderizaÃ§Ã£o em listas grandes

### orcamento-fiscal-municipios
- ETL massivo pode ser lento (5000+ municÃ­pios)
- Necessita cache em queries complexas
- Migrations manuais ainda necessÃ¡rias

---

## ğŸ“ APRENDIZADO CONTÃNUO

### ApÃ³s cada erro/correÃ§Ã£o:
```markdown
1. âœ… Documentar o que deu errado
2. âœ… Atualizar este CLAUDE.md com:
   - âŒ DON'T: [O que nÃ£o fazer]
   - âœ… DO: [Como fazer certo]
3. âœ… Adicionar regra crÃ­tica se for caso grave
```

---

## ğŸ“ QUANDO EM DÃšVIDA

**REGRA DE OURO**: Na dÃºvida, PERGUNTE.

Nunca Ã© melhor "tentar adivinhar" do que perguntar e fazer certo.

---

## ğŸ›¡ï¸ REGRAS DE QUALIDADE E SEGURANÃ‡A (v3.0 - 11/02/2026)

### VALIDAÃ‡ÃƒO OBRIGATÃ“RIA

**Node.js - Usar Zod:**
```javascript
import { z } from 'zod';

const schema = z.object({
  nome: z.string().min(2).max(200),
  email: z.string().email()
});

// Validar antes de processar
const validated = schema.parse(req.body);
```

**Python - Usar Pydantic:**
```python
from pydantic import BaseModel

class RequestBody(BaseModel):
    nome: str
    email: str
```

### CONSTANTES (SEM MAGIC STRINGS)

```javascript
// âŒ PROIBIDO
status = 'ATIVO';

// âœ… OBRIGATÃ“RIO
import { STATUS } from './constants.js';
status = STATUS.ATIVO;
```

### LOGGING ESTRUTURADO

```javascript
// âŒ PROIBIDO
console.log('Erro:', error);

// âœ… OBRIGATÃ“RIO
logger.error('OperaÃ§Ã£o falhou', { error: error.message, context: {} });
```

### RATE LIMITER (APIs PÃºblicas)

```javascript
import rateLimit from 'express-rate-limit';

const limiter = rateLimit({
  windowMs: 60 * 1000,  // 1 minuto
  max: 100              // 100 req/IP
});

app.use('/api', limiter);
```

### REGISTRO DE FONTES DE DADOS (COMPLIANCE)

Todo scraping/API externa deve registrar fonte:
- Nome da fonte
- URL
- Categoria
- Confiabilidade
- Data de coleta

### DEPLOY VIA CI/CD

```
âŒ NUNCA SSH no servidor para deploy
âŒ NUNCA editar arquivos diretamente no servidor

âœ… SEMPRE commit + push â†’ GitHub Actions
âœ… SEMPRE secrets via GitHub Secrets
```

---

**Ãšltima atualizaÃ§Ã£o:** 08/02/2026
**VersÃ£o:** 1.0.0
**Mantenedor:** Fernando (fernando@iconsai.dev)
